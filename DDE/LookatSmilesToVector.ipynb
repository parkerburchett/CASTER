{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parke\\Documents\\GitHub\\CASTER\\DDE\n",
      "you are already in DDE\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "print(os.getcwd())\r\n",
    "try:\r\n",
    "    os.chdir('DDE')\r\n",
    "except:\r\n",
    "    print('you are already in DDE')\r\n",
    "\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils import data\r\n",
    "from torch import nn \r\n",
    "import copy\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from time import time\r\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "torch.manual_seed(2)    # reproducible torch:2 np:3\r\n",
    "np.random.seed(3)\r\n",
    "\r\n",
    "from dde_config import dde_NN_config\r\n",
    "from dde_torch import dde_NN_Large_Predictor\r\n",
    "from stream_dde import supData, unsupData, smiles2index, smiles2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1722,)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_smiles = ['Clc1ccccc1-c1nc(-c2ccccc2)n[nH]1','COc1ccccc1C(c1nnnn1C(C)(C)C)N1CCN(Cc2ccncc2)CC1']\r\n",
    "\r\n",
    "vector = smiles2vector(sample_smiles[0],sample_smiles[1]) # pass this function \r\n",
    "vector.shape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = vector[vector >0]\r\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[623, 282, 28, 196, 180, 317, 25, 154, 29]\n",
      "[101, 282, 69, 196, 921, 324, 973, 447, 205, 89, 105, 25, 651, 127]\n"
     ]
    }
   ],
   "source": [
    "i1, i2 = smiles2index(sample_smiles[0],sample_smiles[1])\r\n",
    "print(i1) # I think these are the indexes of the vector to switch to on\r\n",
    "print(i2)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are in stream_dde.py \r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "from torch.utils import data\r\n",
    "\r\n",
    "from subword_nmt.apply_bpe import BPE\r\n",
    "import codecs # in the standard python library\r\n",
    "dataFolder = './data'\r\n",
    "\r\n",
    "vocab_path = dataFolder + '/codes.txt' # this is a predefined set of common pseduo functional groups defined as common patterns\r\n",
    "bpe_codes_fin = codecs.open(vocab_path)\r\n",
    "bpe = BPE(bpe_codes_fin, merges=-1, separator='')\r\n",
    "\r\n",
    "vocab_map = pd.read_csv(dataFolder + '/subword_units_map.csv')\r\n",
    "idx2word = vocab_map['index'].values\r\n",
    "words2idx = dict(zip(idx2word, range(0, len(idx2word)))) # I think this creates a dictionary \r\n",
    "max_set = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2idx['#'] # dictionary of pseudo funcitonal groups\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clc1ccccc1-c1nc(-c2ccccc2)n[nH]1\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Cl', 'c1ccccc1', '-', 'c1n', 'c(-', 'c2ccccc2)', 'n', '[nH]', '1']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = bpe.process_line(sample_smiles[0]).split() # this line takes a smile string and breaks into functional groups\r\n",
    "print(sample_smiles[0])\r\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_codes_fin.read() # this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "def get_func_groups(smile, bpe) -> list:\r\n",
    "   return bpe.process_line(smile).split()\r\n",
    "\r\n",
    "def func_groups_to_vector(func_list, functional_group_index_dict)-> np.array:\r\n",
    "   indexes =  [functional_group_index_dict[group] for group in func_list] \r\n",
    "   vector_of_smile =v1 = np.zeros(len(functional_group_index_dict),) # initalize as zeros.\r\n",
    "   vector_of_smile[indexes] = 1 # assign all the index of pseudo functional groups present in smile to be 1.\r\n",
    "   return vector_of_smile\r\n",
    "\r\n",
    "def smile_to_vector(smile, bpe, functional_group_index_dict) ->np.array:\r\n",
    "   \"\"\"\r\n",
    "      You should make your own dictionaries for bpe and for functional group index for your own dataset. I don't know what would be best for that\r\n",
    "   \"\"\"\r\n",
    "   functional_groups = get_func_groups(smile, bpe)\r\n",
    "   vector = func_groups_to_vector(functional_groups, functional_group_index_dict)\r\n",
    "   return vector\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "from tdc.single_pred import ADME\r\n",
    "data = ADME(name = 'CYP2C9_Veith')  # this is the binary classification problem\r\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split['train'][['Drug', 'Y']]\r\n",
    "\r\n",
    "\r\n",
    "# this is inefficent but that does not matter now just proof of concept\r\n",
    "\r\n",
    "drugs = df['Drug']\r\n",
    "vectors = []\r\n",
    "\r\n",
    "for drug in drugs:\r\n",
    "    vec = smile_to_vector(drug,bpe, words2idx)\r\n",
    "    vectors.append(vec)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple Random Forest had an accuray rate of 56.00000000000001%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "model = RandomForestClassifier(max_depth=5, random_state=42, n_estimators =1000)\r\n",
    "Training_size =7000\r\n",
    "X = pd.DataFrame(np.array(vectors))\r\n",
    "y = df['Y']\r\n",
    "model.fit(X.iloc[:Training_size],y.iloc[:Training_size])\r\n",
    "score = model.score(X.iloc[Training_size:], y.iloc[Training_size:])\r\n",
    "print(f'A simple Random Forest had an accuray rate of { round(score ,2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There where 0 1s predicted. This is because the training data is unbalenced.\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X.iloc[Training_size:])\r\n",
    "print(f'There where {sum(preds)} 1s predicted. This is because the training data is unbalenced.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1712</th>\n      <th>1713</th>\n      <th>1714</th>\n      <th>1715</th>\n      <th>1716</th>\n      <th>1717</th>\n      <th>1718</th>\n      <th>1719</th>\n      <th>1720</th>\n      <th>1721</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8460</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8461</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8462</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8463</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8464</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8465 rows × 1722 columns</p>\n</div>",
      "text/plain": "      0     1     2     3     4     5     6     7     8     9     ...  1712  \\\n0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n4      0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...   0.0   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n8460   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n8461   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n8462   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n8463   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n8464   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n\n      1713  1714  1715  1716  1717  1718  1719  1720  1721  \n0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n8460   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n8461   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n8462   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n8463   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n8464   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[8465 rows x 1722 columns]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 2813 1 targets and 5652 0 targets\n"
     ]
    }
   ],
   "source": [
    "print(f'there are {sum(y)} 1 targets and {len(y) -sum(y)} 0 targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy predicts that everything is a 0 becasue 3/4 of targets are 0s.\r\n",
    "To address this I am going to balence the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Regressor after balancing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X\r\n",
    "num_functional_groups = (train_df == 1).astype(int).sum(axis=1) # this just counts the 1s in each row.\r\n",
    "train_df['num_functional_groups'] = num_functional_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5652\n",
      "1    2813\n",
      "Name: Y, dtype: int64\n",
      "11    1007\n",
      "10     974\n",
      "9      914\n",
      "12     907\n",
      "13     732\n",
      "8      669\n",
      "14     548\n",
      "7      543\n",
      "15     415\n",
      "6      372\n",
      "16     284\n",
      "5      235\n",
      "17     191\n",
      "4      136\n",
      "18     133\n",
      "19      94\n",
      "3       64\n",
      "20      58\n",
      "21      49\n",
      "22      30\n",
      "23      27\n",
      "24      24\n",
      "2       15\n",
      "25      12\n",
      "26      10\n",
      "29       5\n",
      "28       4\n",
      "27       3\n",
      "34       3\n",
      "30       3\n",
      "36       1\n",
      "37       1\n",
      "38       1\n",
      "31       1\n",
      "Name: num_functional_groups, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\r\n",
    "print(train_df['num_functional_groups'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Count')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['num_functional_groups'].hist()\r\n",
    "plt.title('Number of functional groups in each molecule in the training data')\r\n",
    "plt.xlabel('Num Functional Groups')\r\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance with Random Oversampling. \r\n",
    "\r\n",
    "1. This naive method just randomly resamples each category to be the same size. Because there are fewer 1s than 0s this method increases the size of the training data to add more examples of vectors with 1s.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    5652\n1    5652\nName: Y, dtype: int64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "ros = RandomOverSampler(random_state=0)\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\r\n",
    "X_resampled = pd.DataFrame(X_resampled)\r\n",
    "y_resampled.value_counts()\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model with random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1714</th>\n      <th>1715</th>\n      <th>1716</th>\n      <th>1717</th>\n      <th>1718</th>\n      <th>1719</th>\n      <th>1720</th>\n      <th>1721</th>\n      <th>num_functional_groups</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1724 columns</p>\n</div>",
      "text/plain": "     0    1    2    3    4    5    6    7    8    9  ...  1714  1715  1716  \\\n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...   0.0   0.0   0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n\n   1717  1718  1719  1720  1721  num_functional_groups  target  \n0   0.0   0.0   0.0   0.0   0.0                      9       1  \n1   0.0   0.0   0.0   0.0   0.0                     15       1  \n2   0.0   0.0   0.0   0.0   0.0                     11       0  \n3   0.0   0.0   0.0   0.0   0.0                     16       1  \n4   0.0   0.0   0.0   0.0   0.0                     11       0  \n\n[5 rows x 1724 columns]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample_df = X_resampled\r\n",
    "oversample_df['target'] =y_resampled\r\n",
    "oversample_df = oversample_df.sample(frac=1).reset_index(drop=True) # shuffle the rows\r\n",
    "\r\n",
    "oversample_df.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest with random oversampling is 0.7607361963190185\n"
     ]
    }
   ],
   "source": [
    "over_sample_model = RandomForestClassifier(max_depth=5, random_state=42, n_estimators =1000, max_samples=100)\r\n",
    "training_size = 10000\r\n",
    "over_sample_model.fit(X_resampled.iloc[:training_size], y_resampled[:training_size])\r\n",
    "score = over_sample_model.score(X_resampled.iloc[training_size:], y_resampled[training_size:])\r\n",
    "print(f'The accuracy of the Random Forest with random oversampling is {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    6737\n1    3263\ndtype: int64"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = over_sample_model.predict(X_resampled.iloc[:training_size])\r\n",
    "print(preds.shape)\r\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion of dummy model testing\r\n",
    "\r\n",
    "1. The data is not ballenced.%\r\n",
    "2. The base line random forest with 1 hot encoding and a num_functional_groups column had an accuray rate on a subset of the training data of 74%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5  ('venv': venv)",
   "name": "pythonjvsc74a57bd04e7892b4f467507d725e34517222c9d31081f1c74175e58fa588dd5bafca0b86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "4e7892b4f467507d725e34517222c9d31081f1c74175e58fa588dd5bafca0b86"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}